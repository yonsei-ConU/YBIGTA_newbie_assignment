# LLM 과제 보고서

## 정답률 정리
| Prompting Method   | 0-shot Accuracy | 3-shot Accuracy | 5-shot Accuracy |
|--------------------|-----------------|-----------------|-----------------|
| Direct Prompting   | 20.00%          | 20.00%          | 20.00%          |
| CoT Prompting      | 30.00%          | 34.00%          | 38.00%          |
| My Prompting       | 58.00%          | 50.00%          | 36.67%          |

## 결과 분석
구현해본 것은 다음과 같은 세 가지이다.
- Direct Prompting
- CoT Prompting
- My Prompting (Custom)

### Direct Prompting
Direct의 경우 chain of thought에 대한 언급을 전혀 하지 않고 단순히 정답만 출력하라는 방식으로 프롬프트를 구성했다.  
그 결과 0-shot, 3-shot, 5-shot 모두 20%의 낮은 정확성을 보였다.

### CoT Prompting
CoT의 경우 CoT 과정을 보여주며, 답을 한 번 내고 나면 그 답이 맞는지 다시 검증하는 과정까지 하게끔 프롬프트를 구성했다.  
그랬더니 0-shot의 경우 30%, 3-shot의 경우 34%, 5-shot의 경우 38%의 정확성을 보였다.  
Direct Prompting과 비교했을 때 유의미하게 높은 성능을 보임을 확인할 수 있었고, shot이 늘어나면 늘어날수록 정확성이 점점 높아지는 양상을 확인해볼 수 있었다.  
CoT는 어쨌든 답을 내기 전 중간의 추론 과정을 명시하게 만들어 모델이 문제를 올바른 과정에 따라 풀 수 있도록 도와준다는 점에서 Direct Prompting보다는 성능이 좋을 수밖에 없다고 생각한다.  

### My Prompting
CoT로 얻은 정확성이 Direct Prompting보다는 유의미하게 높은 것은 부정할 수 없지만, 그렇다고 해서 30%대의 정확성이 높은 정확성이라고 볼 수는 없을 것 같다.  
그래서 CoT를 돌렸음에도 정확성이 높지 않게 나오는 이유를 조사했는데 프롬프트 자체가 너무 길어서일 수 있다는 내용을 보게 되었다.  
프롬프트의 길이가 길어져서 문제가 생기므로, 답이 맞는지 다시 검증하는 과정을 빼서라도 프롬프트 길이를 조금 더 짧게 만들어보자는 마음으로, 검증하는 과정을 과감이 뺐다.  
그랬더니 0-shot에서 58%, 3-shot에서 50%, 5-shot에서 36.67%의 정확성을 보였다.  
5-shot에서 정확성이 2% 단위로 떨어지지 않은 이유는 중간에 API 제한이 걸렸기 때문인데, 제한 초기화되는 거 보고 나서 다시 돌렸는데도 API 제한에 걸리는 것을 보면 이 프롬프트가 API 토큰을 굉장히 많이 소모하는 것 같다. CoT에 비해 프롬프트의 길이는 짧아졌음에도 이런 일이 일어난 이유는 찾지 못했다.  
이 방법이 이전에 구현했던 방법보다 더 나은 이유는 확실히 프롬프트 길이가 줄었기 때문이라고 해석할 수 있는데, 오히려 답을 재검증하는 부분을 제외시켰는데도 정확성이 올라간 걸 보면 프롬프트 길이 때문이라고 해석하는 것이 자연스러워 보인다.  
마지막으로 shot이 늘어날수록 이번에는 오히려 정확성이 떨어지는 결과가 나왔는데, 이도 프롬프트의 길이 때문이라고 해석했다.
